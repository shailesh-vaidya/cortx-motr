<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Motr: LNet Transport DLD</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Motr
   &#160;<span id="projectnumber">M0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('d6/de0/_l_net_d_l_d.html','../../');});
/* @license-end */
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">LNet Transport DLD </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-ovw">Overview</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-def">Definitions</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-req">Requirements</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-depends">Dependencies</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-highlights">Design Highlights</a></li>
<li><a class="el" href="../../d5/ddd/_l_net_d_l_d-fspec.html">Functional Specification</a><ul>
<li><a class="el" href="../../d7/db9/group___l_net_d_f_s.html">LNet Transport</a> <br />
 - <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html">XO Interface</a> <br />
 - <a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec">Logical Specification</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-comps">Component Overview</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-ep">End Point Support</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-start">Transfer Machine Start</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-stop">Transfer Machine Termination</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-bev-sync">Synchronous Network Buffer Event Delivery</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-thread">Transfer Machine Event Processing Thread</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-buf-nbd">Network Buffer Descriptor</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-buf-op">Buffer operations</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-state">State Specification</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-thread">Threading and Concurrency Model</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-numa">NUMA optimizations</a></li>
</ul>
</li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-conformance">Conformance</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-ut">Unit Tests</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-st">System Tests</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-O">Analysis</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-ref">References</a></li>
</ul>
<hr/>
 <h1><a class="anchor" id="LNetDLD-ovw"></a>
Overview</h1>
<p>This document describes the Motr network transport for LNet. The transport is composed of multiple layers. The document describes the layering and then focuses mainly on the transport operations layer.</p>
<p>The design of the other layers can be found here:</p><ul>
<li><a class="el" href="../../da/d12/_l_net_core_d_l_d-fspec.html">LNet Transport Core API</a></li>
</ul>
<p><br />
 - <a class="el" href="../../de/d4e/_l_netcqueue_d_l_d.html">LNet Buffer Event Circular Queue DLD</a></p>
<p><br />
 - <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html">LNet Transport Kernel Core DLD</a></p>
<p><br />
 - <a class="el" href="../../d8/d7d/_u_l_net_core_d_l_d.html">LNet Transport User Space Core DLD</a></p>
<p><br />
 - <a class="el" href="../../da/d74/_l_net_d_r_v_d_l_d.html">LNet Transport Device DLD</a></p>
<p><br />
 </p><hr/>
 <h1><a class="anchor" id="LNetDLD-def"></a>
Definitions</h1>
<ul>
<li>HLD of Motr LNet Transport : For documentation links, please refer to this file : doc/motr-design-doc-list.rst</li>
</ul>
<hr/>
 <h1><a class="anchor" id="LNetDLD-req"></a>
Requirements</h1>
<ul>
<li><b>r.m0.net.xprt.lnet.transport-variable</b> The implementation shall name the transport variable as specified in the HLD.</li>
<li><b>r.m0.net.lnet.buffer-registration</b> Provide support for hardware optimization through buffer pre-registration.</li>
<li><b>r.m0.net.xprt.lnet.end-point-address</b> The implementation should support the mapping of end point address to LNet address as described in the Refinement section of the HLD.</li>
<li><b>r.m0.net.xprt.lnet.multiple-messages-in-buffer</b> Provide support for this feature as described in the HLD.</li>
<li><b>r.m0.net.xprt.lnet.dynamic-address-assignment</b> Provide support for dynamic address assignment as described in the HLD.</li>
<li><b>r.m0.net.xprt.lnet.processor-affinity</b> The implementation must support processor affinity as described in the HLD.</li>
<li><b>r.m0.net.xprt.lnet.user-space</b> The implementation must accommodate the needs of the user space LNet transport.</li>
<li><b>r.m0.net.synchronous-buffer-event-delivery</b> The implementation must provide support for this feature as described in the HLD.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="LNetDLD-depends"></a>
Dependencies</h1>
<ul>
<li>
<p class="startli"><a class="el" href="../../d8/de0/group___l_net_core.html">LNet Transport Core Interface</a> </p>
<p class="endli"></p>
</li>
<li>
<p class="startli">The <a class="el" href="../../d9/dd2/group__net.html">Networking Module</a>. Some modifications are required:</p>
<p>The design adds two additional fields to the <a class="el" href="../../d9/d7e/structm0__net__buffer.html">m0_net_buffer</a> structure: </p><div class="fragment"><div class="line"><span class="keyword">struct </span><a class="code" href="../../d9/d7e/structm0__net__buffer.html">m0_net_buffer</a> {</div><div class="line">   ...</div><div class="line">   <a class="code" href="../../d9/d49/types_8h.html#a754ca36f0e1fff3edef4f267024b1a1f">m0_bcount_t</a>   <a class="code" href="../../d9/d7e/structm0__net__buffer.html#afe5d922cf167f088388084c3d5622593">nb_min_receive_size</a>;</div><div class="line">   uint32_t      <a class="code" href="../../d9/d7e/structm0__net__buffer.html#ac27f90ab817e14a76fcc4bf62d3d9998">nb_max_receive_msgs</a>;</div><div class="line">};</div></div><!-- fragment --><p> These fields are required to be set to non-zero values in receive buffers, and control the reception of multiple messages into a single receive buffer.</p>
<p>Additionally, the semantics of the <code>nb_ep</code> field is modified to not require the end point of the active transfer machine when enqueuing a passive buffer. This effectively says that there will be no constraint on which transfer machine performs the active operation, and the application with the passive buffer is not required to know the address of this active transfer machine in advance. This enables the conveyance of the network buffer descriptor to the active transfer machine through intermediate proxies, and the use of load balancing algorithms to spread the I/O traffic across multiple servers.</p>
<p>The <a class="el" href="../../d9/dd2/group__net.html#gac1fd8e90b9cc27145764db8503e77a46">m0_net_tm_confine()</a> subroutine is added to set the processor affinity for transfer machine thread if desired. This results in an additional operation being added to the <a class="el" href="../../da/dca/structm0__net__xprt__ops.html">m0_net_xprt_ops</a> structure:</p>
<div class="fragment"><div class="line"><span class="keyword">struct </span><a class="code" href="../../da/dca/structm0__net__xprt__ops.html">m0_net_xprt_ops</a> {</div><div class="line">   ...</div><div class="line">   <a class="code" href="../../d6/dca/namespaceerror__injection.html#a61569f2965b7a369eb10b6d75d410d11">int</a>  (*<a class="code" href="../../da/dca/structm0__net__xprt__ops.html#a2c1ca11e4851774839799481af1aa7b6">xo_tm_confine</a>)(<span class="keyword">struct </span><a class="code" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a> *tm,</div><div class="line">                         <span class="keyword">const</span> <span class="keyword">struct </span><a class="code" href="../../d9/d78/structm0__bitmap.html">m0_bitmap</a> *processors);</div><div class="line">};</div></div><!-- fragment --><p>The behavior of the <a class="el" href="../../d9/dd2/group__net.html#gaff7a97dce21f4689aba444caaf0dc00b">m0_net_buffer_event_post()</a> subroutine is modified slightly to allow for multiple buffer events to be delivered for a single receive buffer, without removing it from a transfer machine queue. This is indicated by the <a class="el" href="../../d9/dd2/group__net.html#gga1936206a7485cc1c14e35c6e0d348a38a83ca4bce210bde991f2794ea9d5e54e8">M0_NET_BUF_RETAIN</a> flag.</p>
<p>The design adds the following fields to the <a class="el" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a> structure to support the synchronous delivery of network buffer events: </p><div class="fragment"><div class="line"><span class="keyword">struct </span><a class="code" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a> {</div><div class="line">   ...</div><div class="line">   <span class="keywordtype">bool</span>                        <a class="code" href="../../d4/d78/structm0__net__transfer__mc.html#a18592d3fff3f7ac0aa6a9005b1847e7e">ntm_bev_auto_deliver</a>;</div><div class="line">};</div></div><!-- fragment --><p> By default, <code>ntm_bev_auto_deliver</code> is set to <code>true</code>. In addition the following subroutines are defined:</p><ul>
<li><a class="el" href="../../d9/dd2/group__net.html#gac14378833476363fc5dce912b9481de1">m0_net_buffer_event_deliver_all()</a></li>
<li><a class="el" href="../../d9/dd2/group__net.html#ga3dcea028a826a4f4fdd3dc392b496fe6">m0_net_buffer_event_deliver_synchronously()</a></li>
<li><a class="el" href="../../d9/dd2/group__net.html#ga0aaa79c77e39a4e205502f9b86333b37">m0_net_buffer_event_pending()</a></li>
<li><a class="el" href="../../d9/dd2/group__net.html#gad257823f54d86f2891741986a8a190bb">m0_net_buffer_event_notify()</a></li>
</ul>
<p>This results in corresponding operations being added to the <a class="el" href="../../da/dca/structm0__net__xprt__ops.html">m0_net_xprt_ops</a> structure: </p><div class="fragment"><div class="line"><span class="keyword">struct </span><a class="code" href="../../da/dca/structm0__net__xprt__ops.html">m0_net_xprt_ops</a> {</div><div class="line">   ...</div><div class="line">   void (*<a class="code" href="../../da/dca/structm0__net__xprt__ops.html#a682b0ef3af0d6ff5a18a4eee40fa81a7">xo_bev_deliver_all</a>)(<span class="keyword">struct </span><a class="code" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a> *tm);</div><div class="line">   <a class="code" href="../../d6/dca/namespaceerror__injection.html#a61569f2965b7a369eb10b6d75d410d11">int</a>  (*<a class="code" href="../../da/dca/structm0__net__xprt__ops.html#a13f8b1a9ebc3fa1779628ad04781295e">xo_bev_deliver_sync</a>)(<span class="keyword">struct </span><a class="code" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a> *tm);</div><div class="line">   bool (*<a class="code" href="../../da/dca/structm0__net__xprt__ops.html#ae7616c29b043695f8c7e47426bd89fdc">xo_bev_pending</a>)(<span class="keyword">struct </span><a class="code" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a> *tm);</div><div class="line">   void (*<a class="code" href="../../da/dca/structm0__net__xprt__ops.html#ac1cc7774916c4f92e7b1feeb991c6a42">xo_bev_notify</a>)(<span class="keyword">struct </span><a class="code" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a> *tm,</div><div class="line">                         <span class="keyword">struct </span><a class="code" href="../../d0/d12/structm0__chan.html">m0_chan</a> *<a class="code" href="../../d8/d57/rdwr__test__bench_8c.html#a75b25076e6274990c36afcf04b70a53c">chan</a>);</div><div class="line">};</div></div><!-- fragment --><p></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">The <a class="el" href="../../df/df3/group__bitmap.html">Bitmap Module</a>. New subroutines to copy a bitmap and to compare bitmaps are required. The copy subroutine should be refactored out of the processors_copy_m0bitmap() subroutine. </p>
<p class="endli"></p>
</li>
<li>
<p class="startli">The <a class="el" href="../../d7/da7/group__processor.html#Processor">Processor</a> API for the application to determine processor bitmaps with which to specify thread affinity.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">The <a class="el" href="../../da/dd8/group__thread.html">Thread Module</a>. Modifications are required in <a class="el" href="../../da/dd8/group__thread.html#ga1d5a14e0c35f5668f08ad52efb9e8afd">m0_thread_init()</a> subroutine or a variant should be provided to support thread creation with processor affinity set. This is essential for the kernel implementation where processor affinity can only be set during thread creation.</p>
<p class="endli"></p>
</li>
</ul>
<hr/>
 <h1><a class="anchor" id="LNetDLD-highlights"></a>
Design Highlights</h1>
<ul>
<li>Common user and kernel space implementation over an underlying "Core" I/O layer that communicates with the kernel LNet module.</li>
<li>Supports the reception of multiple messages in a single receive buffer.</li>
<li>Provides processor affinity.</li>
<li>Support for hardware optimizations in buffer access.</li>
<li>Support for dynamic transfer machine identifier assignment.</li>
<li>Efficient communication between user and kernel address spaces in the user space transport through the use of shared memory. This includes the efficient conveyance of buffer operation completion event data through the use of a circular queue in shared memory, and the minimal use of system calls to block for events.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="LNetDLD-lspec"></a>
Logical Specification</h1>
<ul>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-comps">Component Overview</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-ep">End Point Support</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-start">Transfer Machine Start</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-stop">Transfer Machine Termination</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-bev-sync">Synchronous Network Buffer Event Delivery</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-thread">Transfer Machine Event Processing Thread</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-buf-nbd">Network Buffer Descriptor</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-buf-op">Buffer operations</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-state">State Specification</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-thread">Threading and Concurrency Model</a></li>
<li><a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-numa">NUMA optimizations</a></li>
</ul>
<h2><a class="anchor" id="LNetDLD-lspec-comps"></a>
Component Overview</h2>
<p>The focus of the LNet transport is the implementation of the asynchronous semantics required by the Motr Networking layer. I/O is performed by an underlying "core" layer, which does the actual interaction with the Lustre LNet kernel module. The core layer permits the LNet transport code to be written in an address space agnostic fashion, as it offers the same interface in both user and kernel space.</p>
<p>The relationship between the various components of the LNet transport and the networking layer is illustrated in the following UML diagram. </p><div class="image">
<img src="../../../../net/lnet/lnet_xo.png" alt="lnet_xo.png"/>
<div class="caption">
LNet Transport Objects</div></div>
<p> <br />
 </p>
<h2><a class="anchor" id="LNetDLD-lspec-ep"></a>
End Point Support</h2>
<p>The transport defines the following structure for the internal representation of a struct <a class="el" href="../../d2/d80/structm0__net__end__point.html">m0_net_end_point</a>. </p><div class="fragment"><div class="line"><span class="keyword">struct </span><a class="code" href="../../d1/df1/structnlx__xo__ep.html">nlx_xo_ep</a> {</div><div class="line">    uint64_t                <a class="code" href="../../d1/df1/structnlx__xo__ep.html#a63f6a25754252eb76a173087902e3645">xe_magic</a>;</div><div class="line">    <span class="keyword">struct </span><a class="code" href="../../d2/d80/structm0__net__end__point.html">m0_net_end_point</a> <a class="code" href="../../d1/df1/structnlx__xo__ep.html#ae04a748295b9c1fb5747e8647cd26199">xe_ep</a>;</div><div class="line">    <span class="keyword">struct </span><a class="code" href="../../dc/de3/structnlx__core__ep__addr.html">nlx_core_ep_addr</a> <a class="code" href="../../d1/df1/structnlx__xo__ep.html#a60dded54675c746e83d809a456070ceb">xe_core</a>;</div><div class="line">    <span class="keywordtype">char</span>                    <a class="code" href="../../d1/df1/structnlx__xo__ep.html#a946082007c47a0075643ca7afa2e67f1">xe_addr</a>[<a class="code" href="../../d7/db9/group___l_net_d_f_s.html#ggae29c89b0f3c72163f95695c230c0740ca95a0369ea6df1e42f8db18df8b44ea66">M0_NET_LNET_XEP_ADDR_LEN</a>];</div><div class="line">};</div></div><!-- fragment --><p> The length of the structure depends on the length of the string representation of the address, which must be saved in the <code>xe_addr</code> array. The address of the <code>xe_ep</code> field is returned as the external representation.</p>
<p>The end point data structure is not associated internally with any LNet kernel resources.</p>
<p>The transport does not support dynamic addressing: i.e. the <code>addr</code> parameter can never be NULL in the <a class="el" href="../../d9/dd2/group__net.html#ga156c33ba284b2a346414c38891148114">m0_net_end_point_create()</a> subroutine. However, it supports the dynamic assignment of transfer machine identifiers as described in the HLD, but only for the <code>addr</code> parameter of the <a class="el" href="../../d9/dd2/group__net.html#ga13d554760e4fc59ffb3428fe81b63555">m0_net_tm_start()</a> subroutine.</p>
<p>A linked list of all end point objects created for a transfer machine is maintained in the <a class="el" href="../../d4/d78/structm0__net__transfer__mc.html#a4d20259926d66ad4922f26d196260c97">m0_net_transfer_mc::ntm_end_points</a> list. Objects are added to this list as a result of the application invoking the <a class="el" href="../../d9/dd2/group__net.html#ga156c33ba284b2a346414c38891148114">m0_net_end_point_create()</a> subroutine, or as a side effect of receiving a message. Access to this list is protected by the transfer machine mutex.</p>
<h2><a class="anchor" id="LNetDLD-lspec-tm-start"></a>
Transfer Machine Start</h2>
<p>The <a class="el" href="../../d9/dd2/group__net.html#ga13d554760e4fc59ffb3428fe81b63555">m0_net_tm_start()</a> subroutine is used to start a transfer machine, which results in a call to <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga95e95b2526091b50996ee350fb5dfda9">nlx_xo_tm_start()</a>. The subroutine decodes the end point address using the <a class="el" href="../../d8/de0/group___l_net_core.html#gadcf9e5c3e6a5615f874f8df656cc0298">nlx_core_ep_addr_decode()</a> subroutine. It then starts the background event processing thread with the desired processor affinity. The thread will complete the transfer machine start up and deliver its state change event.</p>
<p>The event processing thread will call the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga320b9bd08fca9515d270a582f7a2dc3f">nlx_core_tm_start()</a> subroutine to create the internal LNet EQ associated with the transfer machine. This call also validates the transfer machine's address, and assigns a dynamic transfer machine identifier if needed. It will then post a state change callback to transition the transfer machine to its normal operational state, or fail it if any error is encountered.</p>
<h2><a class="anchor" id="LNetDLD-lspec-tm-stop"></a>
Transfer Machine Termination</h2>
<p>Termination of a transfer machine is requested through the <a class="el" href="../../d9/dd2/group__net.html#ga9858ef0b4919bdf6b5abd5fd4186b53a">m0_net_tm_stop()</a> subroutine, which results in a call to <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#gac218309f3cae3f0900be05ff1ee217fb">nlx_xo_tm_stop()</a>. The latter ensures that the transfer machine's thread wakes up by signaling on the <a class="el" href="../../da/de5/structnlx__xo__transfer__mc.html#a52f4649ab98b777d2a313536f948bdd7">nlx_xo_transfer_mc::xtm_ev_cond</a> condition variable.</p>
<p>When terminating a transfer machine the application has a choice of draining current operations or aborting such activity. If the latter choice is made, then the transport must first cancel all operations.</p>
<p>Regardless, the transfer machine's event processing thread completes the termination process. It waits until all buffer queues are empty and any ongoing synchronous network buffer delivery has completed, then invokes the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga40d158d51d960ab794120b77560e06a3">nlx_core_tm_stop()</a> subroutine to free the LNet EQ and other resources associated with the transfer machine. It then posts the transfer machine state change event and terminates itself. See <a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-thread">Transfer Machine Event Processing Thread</a> for further detail.</p>
<h2><a class="anchor" id="LNetDLD-lspec-bev-sync"></a>
Synchronous Network Buffer Event Delivery</h2>
<p>The transport supports the optional synchronous network buffer event delivery as required by the HLD. The default asynchronous delivery of buffer events is done by the <a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-thread">Transfer Machine Event Processing Thread</a>. Synchronous delivery must be enabled before the transfer machine is started, and is indicated by the value of the <a class="el" href="../../d4/d78/structm0__net__transfer__mc.html#a18592d3fff3f7ac0aa6a9005b1847e7e">m0_net_transfer_mc::ntm_bev_auto_deliver</a> value being <code>false</code>.</p>
<p>The <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga3b6394372e53f5a224d4769915c0db19">nlx_xo_bev_deliver_sync()</a> transport operation is invoked to disable the automatic delivery of buffer events. The subroutine simply returns without error, and the invoking <a class="el" href="../../d9/dd2/group__net.html#ga3dcea028a826a4f4fdd3dc392b496fe6">m0_net_buffer_event_deliver_synchronously()</a> subroutine will then set the value of <a class="el" href="../../d4/d78/structm0__net__transfer__mc.html#a18592d3fff3f7ac0aa6a9005b1847e7e">m0_net_transfer_mc::ntm_bev_auto_deliver</a> value to <code>false</code>.</p>
<p>The <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga0bb1d1531087ab3c7e94324770b92679">nlx_xo_bev_pending()</a> transport operation is invoked from the <a class="el" href="../../d9/dd2/group__net.html#ga0aaa79c77e39a4e205502f9b86333b37">m0_net_buffer_event_pending()</a> subroutine to determine if there are pending network buffer events. It invokes the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine with a timeout of 0 and uses the returned status value to determine if events are present or not.</p>
<p>The <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga9f25f7040a5cf21ed4c97b3e20df9631">nlx_xo_bev_notify()</a> transport operation is invoked from the <a class="el" href="../../d9/dd2/group__net.html#gad257823f54d86f2891741986a8a190bb">m0_net_buffer_event_notify()</a> subroutine. It sets the <a class="el" href="../../da/de5/structnlx__xo__transfer__mc.html#adc3971355759c6fb6adb7d1921bc7900">nlx_xo_transfer_mc::xtm_ev_chan</a> value to the specified wait channel, and signals on the <a class="el" href="../../da/de5/structnlx__xo__transfer__mc.html#a52f4649ab98b777d2a313536f948bdd7">nlx_xo_transfer_mc::xtm_ev_cond</a> condition variable to wake up the event processing thread.</p>
<p>The <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga075ea92e6d12c26fa7036f912cb6a826">nlx_xo_bev_deliver_all()</a> transport operation is invoked from the <a class="el" href="../../d9/dd2/group__net.html#gac14378833476363fc5dce912b9481de1">m0_net_buffer_event_deliver_all()</a> subroutine. It attempts to deliver all pending events. The transfer machine lock is held across the call to the <a class="el" href="../../d8/de0/group___l_net_core.html#gaea683e854b7a488bec4543247128289d">nlx_core_buf_event_get()</a> subroutine to serialize "consumers" of the circular buffer event queue, but is released during event delivery. The <a class="el" href="../../d4/d78/structm0__net__transfer__mc.html#ac25a898a8ec2a7d4876cdd9ee7e5a19d">m0_net_transfer_mc::ntm_callback_counter</a> field is incremented across the call to prevent premature termination when operating outside of the protection of the transfer machine mutex. This is illustrated in the following pseudo-code for <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga075ea92e6d12c26fa7036f912cb6a826">nlx_xo_bev_deliver_all()</a>: </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> <a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a>;</div><div class="line"><span class="keywordtype">bool</span> delivered_events = <span class="keyword">false</span>;</div><div class="line"><a class="code" href="../../dc/da7/assert_8h.html#a1c063bd08f7e1ab3a6e6008ef825d471">M0_PRE</a>(<a class="code" href="../../d0/d04/group__mutex.html#ga0c96633d90ccf7e2ed6ffee75d983975">m0_mutex_is_locked</a>(&amp;tm-&gt;ntm_mutex));</div><div class="line">tm-&gt;ntm_callback_counter++;</div><div class="line"><span class="keywordflow">do</span> { <span class="comment">// consume all pending events</span></div><div class="line">     <span class="keyword">struct </span><a class="code" href="../../d1/d4b/structnlx__core__buffer__event.html">nlx_core_buffer_event</a> lcbe;</div><div class="line">     <span class="keyword">struct </span><a class="code" href="../../db/d0c/structm0__net__buffer__event.html">m0_net_buffer_event</a> nbev;</div><div class="line">     <a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> = <a class="code" href="../../d8/de0/group___l_net_core.html#gaea683e854b7a488bec4543247128289d">nlx_core_buf_event_get</a>(lctm, &amp;lcbe);</div><div class="line">     <span class="keywordflow">if</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> == 0) {</div><div class="line">       <span class="comment">// create end point objects as needed</span></div><div class="line">     }</div><div class="line">     <a class="code" href="../../d0/d04/group__mutex.html#ga18963570792098f5ab3cf3e8ede8046a">m0_mutex_unlock</a>(&amp;tm-&gt;ntm_mutex); <span class="comment">// release lock</span></div><div class="line">     <span class="keywordflow">if</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> == 0) {</div><div class="line">          nbe = ... <span class="comment">// convert the event</span></div><div class="line">          <a class="code" href="../../d9/dd2/group__net.html#gaff7a97dce21f4689aba444caaf0dc00b">m0_net_buffer_event_post</a>(&amp;nbev);</div><div class="line">          delivered_events = <span class="keyword">true</span>;</div><div class="line">     }</div><div class="line">     <a class="code" href="../../d0/d04/group__mutex.html#gae26efdb3a765f750c5992041d6ee2336">m0_mutex_lock</a>(&amp;tm-&gt;ntm_mutex); <span class="comment">// re-acquire lock</span></div><div class="line">} <span class="keywordflow">while</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> == 0);</div><div class="line">tm-&gt;ntm_callback_counter--;</div><div class="line"><span class="keywordflow">if</span> (delivered_events)</div><div class="line">     <a class="code" href="../../df/da0/group__chan.html#gad1968f64b50443b0c89881a2471321da">m0_chan_broadcast</a>(&amp;tm-&gt;ntm_chan);</div></div><!-- fragment --><h2><a class="anchor" id="LNetDLD-lspec-tm-thread"></a>
Transfer Machine Event Processing Thread</h2>
<p>The default behavior of a transfer machine is to automatically deliver buffer events from the Core API's event queue to the application. The Core API guarantees that LNet operation completion events will result in buffer events being enqueued in the order the API receives them, and, in particular, that multiple buffer events for any given receive buffer will be ordered. This is very important for the transport, because it has to ensure that a receive buffer operation is not prematurely flagged as dequeued.</p>
<p>The transport uses exactly one event processing thread to process buffer events from the Core API. This has the following advantages:</p><ul>
<li>The implementation is simple.</li>
<li>It implicitly race-free with respect to receive buffer events.</li>
</ul>
<p>Applications are not expected to spend much time in the event callback, so this simple approach is acceptable.</p>
<p>The application can establish specific processor affiliation for the event processing thread with the <a class="el" href="../../d9/dd2/group__net.html#gac1fd8e90b9cc27145764db8503e77a46">m0_net_tm_confine()</a> subroutine <em>prior</em> to starting the transfer machine. This results in a call to the <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#gad8b371bd12bbf18146c2d1fab215538f">nlx_xo_tm_confine()</a> subroutine, which makes a copy of the desired processor affinity bitmask in <a class="el" href="../../da/de5/structnlx__xo__transfer__mc.html#a2100460f327b4ca16d1b26f06e36c632">nlx_xo_transfer_mc::xtm_processors</a>.</p>
<p>In addition to automatic buffer event delivery, the event processing thread performs the following functions:</p><ul>
<li>Notify the presence of buffer events when synchronous buffer event delivery is enabled</li>
<li>Transfer machine state change event posting</li>
<li>Buffer operation timeout processing</li>
<li>Logging of statistical data</li>
</ul>
<p>The functionality of the event processing thread is best illustrated by the following pseudo-code: </p><div class="fragment"><div class="line"><span class="comment">// start the transfer machine in the Core</span></div><div class="line"><a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> = <a class="code" href="../../d6/d8a/group___k_l_net_core.html#ga320b9bd08fca9515d270a582f7a2dc3f">nlx_core_tm_start</a>(&amp;tm, lctm);</div><div class="line"><span class="keywordflow">if</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> == 0)</div><div class="line">    <a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> = <a class="code" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#gaf1a92754883486e4cc6e9a91a24f99a1">nlx_ep_create</a>(&amp;tmev.nte_ep, tm, &amp;lctm-&gt;ctm_addr);</div><div class="line"><span class="comment">// deliver a M0_NET_TEV_STATE_CHANGE event to transition the TM to</span></div><div class="line"><span class="comment">// the M0_NET_TM_STARTED or M0_NET_TM_FAILED states</span></div><div class="line"><span class="comment">// Set the transfer machine&#39;s end point on success</span></div><div class="line"><a class="code" href="../../d9/dd2/group__net.html#gaf4918bd635674075138b44a33c9044ef">m0_net_tm_event_post</a>(&amp;tmev);</div><div class="line"><span class="keywordflow">if</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> != 0)</div><div class="line">    <span class="keywordflow">return</span>; <span class="comment">// failure</span></div><div class="line"><span class="comment">// loop forever</span></div><div class="line"><span class="keywordflow">while</span> (1) {</div><div class="line">   <a class="code" href="../../d9/de6/group__console.html#gab5627d8d8b095c198e2523c44ca380ac">timeout</a> = ...; <span class="comment">// compute next timeout (short if automatic or stopping)</span></div><div class="line">   <span class="keywordflow">if</span> (tm-&gt;ntm_bev_auto_deliver) {      <span class="comment">// automatic delivery</span></div><div class="line">       <a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> = <a class="code" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait</a>(lctm, <a class="code" href="../../d9/de6/group__console.html#gab5627d8d8b095c198e2523c44ca380ac">timeout</a>);</div><div class="line">       <span class="comment">// buffer event processing</span></div><div class="line">       <span class="keywordflow">if</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> == 0) { <span class="comment">// did not time out - events pending</span></div><div class="line">          <a class="code" href="../../d0/d04/group__mutex.html#gae26efdb3a765f750c5992041d6ee2336">m0_mutex_lock</a>(&amp;tm-&gt;ntm_mutex);</div><div class="line">          <a class="code" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga075ea92e6d12c26fa7036f912cb6a826">nlx_xo_bev_deliver_all</a>(tm);</div><div class="line">          <a class="code" href="../../d0/d04/group__mutex.html#ga18963570792098f5ab3cf3e8ede8046a">m0_mutex_unlock</a>(&amp;tm-&gt;ntm_mutex);</div><div class="line">       }</div><div class="line">   } <span class="keywordflow">else</span> {                             <span class="comment">// application initiated delivery</span></div><div class="line">          <a class="code" href="../../d0/d04/group__mutex.html#gae26efdb3a765f750c5992041d6ee2336">m0_mutex_lock</a>(&amp;tm-&gt;ntm_mutex);</div><div class="line">          <span class="keywordflow">if</span> (lctm.xtm_ev_chan == <a class="code" href="../../db/df8/lib_2user__space_2misc_8h.html#a070d2ce7b6bb7e5c05602aa8c308d0c4">NULL</a>)</div><div class="line">             <a class="code" href="../../da/dea/group__cond.html#ga3e4e4ec5b200b90e7fb6f8eeb4e10fc7">m0_cond_timedwait</a>(lctm-&gt;xtm_ev_cond, <a class="code" href="../../d9/de6/group__console.html#gab5627d8d8b095c198e2523c44ca380ac">timeout</a>);</div><div class="line">          <span class="keywordflow">if</span> (lctm.xtm_ev_chan != <a class="code" href="../../db/df8/lib_2user__space_2misc_8h.html#a070d2ce7b6bb7e5c05602aa8c308d0c4">NULL</a>) {</div><div class="line">             <a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> = <a class="code" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait</a>(lctm, <a class="code" href="../../d9/de6/group__console.html#gab5627d8d8b095c198e2523c44ca380ac">timeout</a>);</div><div class="line">             <span class="keywordflow">if</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> == 0) {</div><div class="line">                 <a class="code" href="../../df/da0/group__chan.html#ga57339950d21ecc706c5f2e623647f122">m0_chan_signal</a>(lctm-&gt;xtm_chan);</div><div class="line">                 lctm.xtm_chan = <a class="code" href="../../db/df8/lib_2user__space_2misc_8h.html#a070d2ce7b6bb7e5c05602aa8c308d0c4">NULL</a>;</div><div class="line">             }</div><div class="line">          }</div><div class="line">          <a class="code" href="../../d0/d04/group__mutex.html#ga18963570792098f5ab3cf3e8ede8046a">m0_mutex_unlock</a>(&amp;tm-&gt;ntm_mutex);</div><div class="line">   }</div><div class="line">   <span class="comment">// do buffer operation timeout processing periodically</span></div><div class="line">   ...</div><div class="line">   <span class="comment">// termination processing</span></div><div class="line">   <span class="keywordflow">if</span> (tm-&gt;ntm_state == <a class="code" href="../../d9/dd2/group__net.html#ggaaa9dbf6c20e7f07dfe6fc3746f6183e2a39b6318d195085ad1ec281a72d6cc70d">M0_NET_TM_STOPPING</a>) {</div><div class="line">         <span class="keywordtype">bool</span> must_stop = <span class="keyword">false</span>;</div><div class="line">         <a class="code" href="../../d0/d04/group__mutex.html#gae26efdb3a765f750c5992041d6ee2336">m0_mutex_lock</a>(&amp;tm-&gt;ntm_mutex);</div><div class="line">         <span class="keywordflow">if</span> (<a class="code" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga4ad0709396e177757d4894620821a56a">all_tm_queues_are_empty</a>(tm) &amp;&amp; tm-&gt;ntm_callback_counter == 0) {</div><div class="line">            <a class="code" href="../../d6/d8a/group___k_l_net_core.html#ga40d158d51d960ab794120b77560e06a3">nlx_core_tm_stop</a>(lctm);</div><div class="line">            must_stop = <span class="keyword">true</span>;</div><div class="line">         }</div><div class="line">         <a class="code" href="../../d0/d04/group__mutex.html#ga18963570792098f5ab3cf3e8ede8046a">m0_mutex_unlock</a>(&amp;tm-&gt;ntm_mutex);</div><div class="line">         <span class="keywordflow">if</span> (must_stop) {</div><div class="line">            <span class="keyword">struct </span><a class="code" href="../../d3/d91/structm0__net__tm__event.html">m0_net_tm_event</a> tmev;</div><div class="line">            <span class="comment">// construct a M0_NET_TEV_STATE_CHANGE event to transition</span></div><div class="line">            <span class="comment">// to the M0_NET_TM_STOPPED state.</span></div><div class="line">            <a class="code" href="../../d9/dd2/group__net.html#gaf4918bd635674075138b44a33c9044ef">m0_net_tm_event_post</a>(&amp;tmev);</div><div class="line">            <span class="keywordflow">break</span>;</div><div class="line">         }</div><div class="line">   }</div><div class="line">   <span class="comment">// Log statistical data periodically using ADDB</span></div><div class="line">   ...</div><div class="line">}</div></div><!-- fragment --><p> (The C++ style comments above are used only because the example is embedded in a Doxygen C comment. C++ comments are not permitted by the Motr coding style.)</p>
<p>A few points to note on the above pseudo-code:</p><ul>
<li>The thread blocks in the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> if the default automatic buffer event delivery mode is set, or on the <a class="el" href="../../da/de5/structnlx__xo__transfer__mc.html#a52f4649ab98b777d2a313536f948bdd7">nlx_xo_transfer_mc::xtm_ev_cond</a> condition variable otherwise. In the latter case, it may also block in the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine if the condition variable is signaled by the <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga9f25f7040a5cf21ed4c97b3e20df9631">nlx_xo_bev_notify()</a> subroutine.</li>
<li>The transfer machine mutex is obtained across the call to dequeue buffer events to serialize with the "other" consumer of the buffer event queue, the <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#gac88a3ce0522654d1cecef0c7023f4b9e">nlx_xo_buf_add()</a> subroutine that invokes the Core API buffer operation initiation subroutines. This is because these subroutines may allocate additional buffer event structures to the queue.</li>
<li>The <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga075ea92e6d12c26fa7036f912cb6a826">nlx_xo_bev_deliver_all()</a> subroutine processes as many events as it can each time around the loop. The call to the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine in the user space transport is expensive as it makes a device driver <code>ioctl</code> call internally.</li>
<li>The thread is responsible for terminating the transfer machine and delivering its termination event. Termination serializes with concurrent invocation of the <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga075ea92e6d12c26fa7036f912cb6a826">nlx_xo_bev_deliver_all()</a> subroutine in the case of synchronous buffer event delivery.</li>
<li>The timeout value can vary depending on the mode of operation. Synchronous network delivery is best served by a long timeout value (in the order of a minute), at least up to the time that the transfer machine is stopping. Automatic buffer event delivery is better served by a short timeout value (in the order of a second). This is because in the user space transport the thread would be blocked in an ioctl call in the kernel, and would not respond in a lively manner to a shutdown request. The timeout value is also dependent on whether the transfer machine is stopping, the buffer operation timeout check period and the statistical recording period.</li>
</ul>
<h2><a class="anchor" id="LNetDLD-lspec-buf-nbd"></a>
Network Buffer Descriptor</h2>
<p>The transport has to define the format of the opaque network buffer descriptor returned to the application, to encode the identity of the passive buffers.</p>
<p>The data structure will be defined by the Core API along the following lines: </p><div class="fragment"><div class="line"><span class="keyword">struct </span><a class="code" href="../../dd/dde/structnlx__core__buf__desc.html">nlx_core_buf_desc</a> {</div><div class="line">     uint64_t                 <a class="code" href="../../dd/dde/structnlx__core__buf__desc.html#a607499a236d594b0f459d4932c8cf714">cbd_match_bits</a>;</div><div class="line">     <span class="keyword">struct </span><a class="code" href="../../dc/de3/structnlx__core__ep__addr.html">nlx_core_ep_addr</a>  <a class="code" href="../../dd/dde/structnlx__core__buf__desc.html#a6eaaafa62a9f9a2c48f57416ecae66f0">cbd_passive_ep</a>;</div><div class="line">     <span class="keyword">enum</span> <a class="code" href="../../d9/dd2/group__net.html#ga4a25e727e622f7aaaedfe8ffa01fa005">m0_net_queue_type</a>   <a class="code" href="../../dd/dde/structnlx__core__buf__desc.html#a500dca32c935f371b4400131012555d9">cbd_qtype</a>;</div><div class="line">     <a class="code" href="../../d9/d49/types_8h.html#a754ca36f0e1fff3edef4f267024b1a1f">m0_bcount_t</a>              <a class="code" href="../../dd/dde/structnlx__core__buf__desc.html#a16a20ee17bbf40454b05016dd7c1c94b">cbd_size</a>;</div><div class="line">};</div></div><!-- fragment --><p>The <a class="el" href="../../d8/de0/group___l_net_core.html#gaf8b803bcbff74c0d50e0efaebfd5d5ea">nlx_core_buf_desc_encode()</a> and <a class="el" href="../../d8/de0/group___l_net_core.html#ga4af40934b690775bf5c1844e078e374c">nlx_core_buf_desc_decode()</a> subroutines are provided by the Core API to generate and process the descriptor. All the descriptor fields are integers, the structure is of fixed length and all values are in little-endian format. No use is made of either the standard XDR or the Motr Xcode modules.</p>
<p>The transport will handle the conversion of the descriptor into its opaque over the wire format by simply copying the memory area, as the descriptor is inherently portable.</p>
<h2><a class="anchor" id="LNetDLD-lspec-buf-op"></a>
Buffer operations</h2>
<p>Buffer operations are initiated through the <a class="el" href="../../da/dca/structm0__net__xprt__ops.html#ac2bbdcdc2df47209fe46f79ebad5051f">m0_net_xprt_ops::xo_buf_add()</a> operation which points to the <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#gac88a3ce0522654d1cecef0c7023f4b9e">nlx_xo_buf_add()</a> subroutine. The subroutine will invoke the appropriate Core API buffer initiation operations.</p>
<p>In passive bulk buffer operations, the transport must first obtain suitable match bits for the buffer using the <a class="el" href="../../d8/de0/group___l_net_core.html#gaf8b803bcbff74c0d50e0efaebfd5d5ea">nlx_core_buf_desc_encode()</a> subroutine. The transport is responsible for ensuring that the assigned match bits are not in use currently; however this step can be ignored with relative safety as the match bit space is very large and the match bit counter will only wrap around after a very long while. These match bits should also be encoded in the network buffer descriptor that the transport must return.</p>
<p>In active bulk buffer operations, the size of the active buffer should be validated against the size of the passive buffer as given in its network buffer descriptor. The <a class="el" href="../../d8/de0/group___l_net_core.html#ga4af40934b690775bf5c1844e078e374c">nlx_core_buf_desc_decode()</a> subroutine should be used to decode the descriptor.</p>
<h2><a class="anchor" id="LNetDLD-lspec-state"></a>
State Specification</h2>
<p>The transport does not introduce its own state model but operates within the framework defined by the Motr Networking Module. In general, resources are allocated to objects of this module by the underlying Core API, and they have to be recovered upon object finalization, and in the particular case of the user space transport, upon process termination if the termination was not orderly.</p>
<p>The resources allocated to the following objects are particularly called out:</p>
<ul>
<li><a class="el" href="../../d9/d7e/structm0__net__buffer.html">m0_net_buffer</a></li>
<li><a class="el" href="../../d4/d78/structm0__net__transfer__mc.html">m0_net_transfer_mc</a></li>
<li><a class="el" href="../../db/d78/structm0__net__domain.html">m0_net_domain</a></li>
<li><a class="el" href="../../d2/d80/structm0__net__end__point.html">m0_net_end_point</a></li>
</ul>
<p>Network buffers enqueued with a transfer machine represent operations in progress. Until they get dequeued, the buffers are associated internally with LNet kernel module resources (MDs and MEs) allocated on their behalf by the Core API.</p>
<p>The transfer machine is associated with an LNet event queue (EQ). The EQ must be created when the transfer machine is started, and destroyed when the transfer machine stops. The transfer machine operates by default in an asynchronous network buffer delivery mode, but can also provide synchronous network buffer delivery for locality sensitive applications like the Motr request handler.</p>
<p>Buffers registered with a domain object are potentially associated with LNet kernel module resources and, if the transport is in user space, additional kernel memory resources as the buffer vector is pinned in memory. De-registration of the buffers releases these resources. The domain object of a user space transport is also associated with an open file descriptor to the device driver used to communicate with the kernel Core API.</p>
<p>End point structures are exposed externally as struct <a class="el" href="../../d2/d80/structm0__net__end__point.html">m0_net_end_point</a>, but are allocated and managed internally by the transport with struct <a class="el" href="../../d1/df1/structnlx__xo__ep.html">nlx_xo_ep</a>. They do not use LNet resources, but just transport address space memory. Their creation and finalization is protected by the transfer machine mutex. They are reference counted, and the application must release all references before attempting to finalize a transfer machine.</p>
<h2><a class="anchor" id="LNetDLD-lspec-thread"></a>
Threading and Concurrency Model</h2>
<p>The transport inherits the concurrency model of the Motr Networking Module. All transport operations are protected by some lock or object state, as described in the document RPC Bulk Transfer Task Plan. For documentation links, please refer to this file : doc/motr-design-doc-list.rst . The Core API is designed to work with this same locking model. The locking order figure is repeated here for convenience: </p><div class="dotgraph">
<img src="../../dot_inline_dotgraph_26.png" alt="dot_inline_dotgraph_26.png" border="0" usemap="#dot_inline_dotgraph_26.map"/>
<map name="dot_inline_dotgraph_26.map" id="dot_inline_dotgraph_26.map"></map>
</div>
<p>The transport only has one thread, its event processing thread. This thread uses the transfer machine lock when serialization is required by the Core API, and also when creating or looking up end point objects when processing receive buffer events. Termination of the transfer machine is serialized with concurrent invocation of the <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga075ea92e6d12c26fa7036f912cb6a826">nlx_xo_bev_deliver_all()</a> subroutine in the case of synchronous buffer event delivery by means of the <a class="el" href="../../d4/d78/structm0__net__transfer__mc.html#ac25a898a8ec2a7d4876cdd9ee7e5a19d">m0_net_transfer_mc::ntm_callback_counter</a> field. See <a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-bev-sync">Synchronous Network Buffer Event Delivery</a> and <a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-thread">Transfer Machine Event Processing Thread</a> for details.</p>
<h2><a class="anchor" id="LNetDLD-lspec-numa"></a>
NUMA optimizations</h2>
<p>The application can establish specific processor affiliation for the event processing thread with the <a class="el" href="../../d9/dd2/group__net.html#gac1fd8e90b9cc27145764db8503e77a46">m0_net_tm_confine()</a> subroutine prior to starting the transfer machine. Buffer completion events and transfer machine state change events will be delivered through callbacks made from this thread.</p>
<p>Even greater locality of reference is obtained with synchronous network buffer event delivery. The application is able to co-ordinate references to network objects and other objects beyond the scope of the network module.</p>
<hr/>
 <h1><a class="anchor" id="LNetDLD-conformance"></a>
Conformance</h1>
<ul>
<li><b>i.m0.net.xprt.lnet.transport-variable</b> The transport variable <code>m0_net_lnet_xprt</code> is provided.</li>
<li><b>i.m0.net.lnet.buffer-registration</b> Buffer registration is required in the network API and results in the corresponding <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#ga1ddeaa7c75bb854cb5ef95458f8ef4a4">nlx_xo_buf_register()</a> subroutine call at the LNet transport layer. This is where hardware optimization can be performed, once LNet provides such APIs.</li>
<li><b>i.m0.net.xprt.lnet.end-point-address</b> Mapping of LNet end point address is handled in the Core API as described in the <a class="el" href="../../da/d12/_l_net_core_d_l_d-fspec.html">LNet Transport Core API</a>.</li>
<li><b>i.m0.net.xprt.lnet.multiple-messages-in-buffer</b> Fields are provided in the <a class="el" href="../../d9/d7e/structm0__net__buffer.html">m0_net_buffer</a> to support multiple message delivery, and the event delivery model includes the delivery of buffer events for receive buffers that do not always dequeue the buffer.</li>
<li><b>i.m0.net.xprt.lnet.dynamic-address-assignment</b> Dynamic transfer machine identifier assignment is provided by <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga320b9bd08fca9515d270a582f7a2dc3f">nlx_core_tm_start()</a>.</li>
<li><b>i.m0.net.xprt.lnet.processor-affinity</b> The <a class="el" href="../../d9/dd2/group__net.html#gac1fd8e90b9cc27145764db8503e77a46">m0_net_tm_confine()</a> API is provided and the LNet transport provides the corresponding <a class="el" href="../../dd/d6e/group___l_net_x_o_d_f_s.html#gad8b371bd12bbf18146c2d1fab215538f">nlx_xo_tm_confine()</a> function.</li>
<li><b>i.m0.net.xprt.lnet.user-space</b> The user space implementation of the Core API utilizes shared memory and reduces context switches required for user-space event processing through the use of a circular queue maintained in shared memory and operated upon with atomic operations.</li>
<li><b>i.m0.net.synchronous-buffer-event-delivery</b> See <a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-bev-sync">Synchronous Network Buffer Event Delivery</a> and <a class="el" href="../../d6/de0/_l_net_d_l_d.html#LNetDLD-lspec-tm-thread">Transfer Machine Event Processing Thread</a> for details.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="LNetDLD-ut"></a>
Unit Tests</h1>
<p>To control symbol exposure, the transport code is compiled using a single C file that includes other C files with static symbols. Unit testing will take advantage of this setup and use conditional renaming of symbols to intercept specific internal interfaces.</p>
<p>The following tests will be performed for the transport operation (xo) layer with a fake Core API. Tests involving the fake Core API ensure that the transport operation layer makes the correct calls to the Core API.</p>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000106">Test:</a></b></dt><dd>Multiple domain creation will be tested.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000107">Test:</a></b></dt><dd>Buffer registration and deregistration will be tested.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000108">Test:</a></b></dt><dd>Multiple transfer machine creation will be tested.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000109">Test:</a></b></dt><dd>Test that the processor affinity bitmask is set in the TM.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000110">Test:</a></b></dt><dd>The transfer machine state change functionality.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000111">Test:</a></b></dt><dd>Initiation of buffer operations will be tested.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000112">Test:</a></b></dt><dd>Delivery of synthetic buffer events will be tested, including multiple receive buffer events for a single receive buffer. Both asynchronous and synchronous styles of buffer delivery will be tested.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000113">Test:</a></b></dt><dd>Management of the reference counted end point objects; the addresses themselves don't have to valid for these tests.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000114">Test:</a></b></dt><dd>Encoding and Decoding of the network buffer descriptor will be tested.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000115">Test:</a></b></dt><dd>Orderly finalization will be tested.</dd></dl>
<hr/>
 <h1><a class="anchor" id="LNetDLD-st"></a>
System Tests</h1>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000116">Test:</a></b></dt><dd>The <code>bulkping</code> system test program will be updated to include support for the LNet transport. This program will be used to test communication between end points on the same system and between remote systems. The program will offer the ability to dynamically allocate a transfer machine identifier when operating in client mode.</dd></dl>
<hr/>
 <h1><a class="anchor" id="LNetDLD-O"></a>
Analysis</h1>
<p>In general, the transport operational layer simply routes data too and from the Core API; this behavior is analyzed in <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html">LNet Transport Kernel Core DLD</a>.</p>
<p><br />
 An area of concern specific to the transport operations layer is the management of end point objects. In particular, the time taken to search the list of end point objects is of O(N) - i.e. a linear search through the list, which is proportional to the number of list items. This search may become expensive if the list grows large - items on the list are reference counted and it is up to the application to release them, not the transport.</p>
<p>The internal end point address fields are all numeric and easily lend themselves to a hash based strategy (the NID value is the best candidate key). The tricky part of any hashing scheme would be to determine what hash function would result in a reasonably even distribution over a set of hash buckets; this is not as bad as it sounds, because even in the worst case, it would degenerate to the linear search we have at present.</p>
<p>Ultimately, the choice of whether to use hashing or not depends on what the behavior of a Motr server will be like in steady state: if end points are released fairly rapidly, the linked list implementation will suffice. Note that since no LNet kernel resources are associated with end point objects, this issue is simply related to search performance.</p>
<hr/>
 <h1><a class="anchor" id="LNetDLD-ref"></a>
References</h1>
<p>For documentation links, please refer to this file : doc/motr-design-doc-list.rst</p><ul>
<li>HLD of Motr LNet Transport</li>
<li>RPC Bulk Transfer Task Plan</li>
<li><a class="el" href="../../de/d4e/_l_netcqueue_d_l_d.html">LNet Buffer Event Circular Queue DLD</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html">LNet Transport Kernel Core DLD</a></li>
<li><a class="el" href="../../d8/d7d/_u_l_net_core_d_l_d.html">LNet Transport User Space Core DLD</a></li>
<li><a class="el" href="../../da/d74/_l_net_d_r_v_d_l_d.html">LNet Transport Device DLD</a> </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../d3/dd6/_d_l_d_i_x.html">Detailed Designs</a></li>
    <li class="footer">Generated on Thu Apr 14 2022 14:03:26 for Motr by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="../../doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>

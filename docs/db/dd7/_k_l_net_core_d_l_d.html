<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Motr: LNet Transport Kernel Core DLD</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Motr
   &#160;<span id="projectnumber">M0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('db/dd7/_k_l_net_core_d_l_d.html','../../');});
/* @license-end */
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">LNet Transport Kernel Core DLD </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-ovw">Overview</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-def">Definitions</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-req">Requirements</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-depends">Dependencies</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-highlights">Design Highlights</a></li>
<li>Functional Specification<ul>
<li><a class="el" href="../../da/d12/_l_net_core_d_l_d-fspec.html">LNet Transport Core API</a></li>
<li><a class="el" href="../../d6/d8a/group___k_l_net_core.html">Core Kernel Interface</a> <br />
 - <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec">Logical Specification</a></li>
</ul>
</li>
</ul>
<p><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-comps">Component Overview</a></p><ul>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-userspace">Support for User Space Transports</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-match-bits">Match Bits for Buffer Identification</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-tm-list">Transfer Machine Uniqueness</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-bevq">The Buffer Event Queue</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-lnet-init">LNet Initialization and Finalization</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-reg">LNet Buffer Registration</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-tm-res">LNet Transfer Machine Resources</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-buf-res">LNet Buffer Resources</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-recv">LNet Receiving Unsolicited Messages</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-send">LNet Sending Messages</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-passive">LNet Staging Passive Bulk Buffers</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-active">LNet Active Bulk Read or Write</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-lnet-cancel">LNet Canceling Operations</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-state">State Specification</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-thread">Threading and Concurrency Model</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-numa">NUMA optimizations</a></li>
</ul>
<p><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-conformance">Conformance</a></p><ul>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-ut">Unit Tests</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-st">System Tests</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-O">Analysis</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-ref">References</a></li>
</ul>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-ovw"></a>
Overview</h1>
<p>The LNet Transport is built over an address space agnostic "core" I/O interface. This document describes the kernel implementation of this interface, which directly interacts with the Lustre LNet kernel module.</p>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-def"></a>
Definitions</h1>
<ul>
<li>HLD of Motr LNet Transport : For documentation links, please refer to this file : doc/motr-design-doc-list.rst</li>
</ul>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-req"></a>
Requirements</h1>
<ul>
<li><b>r.m0.net.lnet.buffer-registration</b> Provide support for hardware optimization through buffer pre-registration.</li>
<li><b>r.m0.net.xprt.lnet.end-point-address</b> The implementation should support the mapping of end point address to LNet address as described in the Refinement section of the HLD.</li>
<li><b>r.m0.net.xprt.lnet.multiple-messages-in-buffer</b> Provide support for this feature as described in the HLD.</li>
<li><b>r.m0.net.xprt.lnet.dynamic-address-assignment</b> Provide support for dynamic address assignment as described in the HLD.</li>
<li><b>r.m0.net.xprt.lnet.user-space</b> The implementation must accommodate the needs of the user space LNet transport.</li>
<li><b>r.m0.net.xprt.lnet.user.no-gpl</b> The implementation must not expose the user space transport to GPL interfaces.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-depends"></a>
Dependencies</h1>
<ul>
<li><b>LNet API</b> headers are required to build the module. The Lustre source package must be installed on the build machine (RPM <code>lustre-source</code> version 2.0 or greater).</li>
<li><b>Lustre run time</b></li>
<li><b>r.m0.lib.atomic.interoperable-kernel-user-support</b> The <a class="el" href="../../de/d4e/_l_netcqueue_d_l_d.html">Buffer Event Circular Queue</a> provides a shared data structure for efficiently passing event notifications from the Core layer to the LNet transport layer.</li>
<li><b>r.net.xprt.lnet.growable-event-queue</b> The <a class="el" href="../../de/d4e/_l_netcqueue_d_l_d.html">Buffer Event Circular Queue</a> provides a way to expand the event queue as new buffers are queued with a transfer machine, ensuring no events are lost.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-highlights"></a>
Design Highlights</h1>
<ul>
<li>The Core API is an address space agnostic I/O interface intended for use by the Motr Networking LNet transport operation layer in either user space or kernel space.</li>
<li>Efficient support for the user space transports is provided by use of cross-address space tolerant data structures in shared memory.</li>
<li>The Core API does not expose any LNet symbols.</li>
<li>Each transfer machine is internally assigned one LNet event queue for all its LNet buffer operations.</li>
<li>Pre-allocation of buffer event space to guarantee that buffer operation results can be returned.</li>
<li>The notification of the completion of a buffer operation to the transport layer is decoupled from the LNet callback that provided this notification to the core module.</li>
<li>The number of messages that can be delivered into a single receive buffer is bounded to support pre-allocation of memory to hold the buffer event payload.</li>
<li>Buffer completion event notification is provided via a semaphore. The design guarantees delivery of events in the order received from LNet. In particular, the multiple possible events delivered for a single receive buffer will be ordered.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-lspec"></a>
Logical Specification</h1>
<ul>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-comps">Component Overview</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-userspace">Support for User Space Transports</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-match-bits">Match Bits for Buffer Identification</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-tm-list">Transfer Machine Uniqueness</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-bevq">The Buffer Event Queue</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-lnet-init">LNet Initialization and Finalization</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-reg">LNet Buffer Registration</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-tm-res">LNet Transfer Machine Resources</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-buf-res">LNet Buffer Resources</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-recv">LNet Receiving Unsolicited Messages</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-send">LNet Sending Messages</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-passive">LNet Staging Passive Bulk Buffers</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-active">LNet Active Bulk Read or Write</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-lnet-cancel">LNet Canceling Operations</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-state">State Specification</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-thread">Threading and Concurrency Model</a></li>
<li><a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-numa">NUMA optimizations</a></li>
</ul>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-comps"></a>
Component Overview</h2>
<p>The relationship between the various objects in the components of the LNet transport and the networking layer is illustrated in the following UML diagram. </p><div class="image">
<img src="../../../../net/lnet/lnet_xo.png" alt="lnet_xo.png"/>
<div class="caption">
LNet Transport Objects</div></div>
<p> The Core layer in the kernel has no sub-components but interfaces directly with the Lustre LNet module in the kernel.</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-userspace"></a>
Support for User Space Transports</h2>
<p>The kernel Core module is designed to support user space transports with the use of shared memory. It does not directly provide a mechanism to communicate with the user space transport, but expects that the user space Core module will provide a device driver to communicate between user and kernel space, manage the sharing of core data structures, and interface between the kernel and user space implementations of the Core API.</p>
<p>The common Core data structures are designed to support such communication efficiently:</p>
<ul>
<li>The core data structures are organized with a distinction between the common directly shareable portions, and private areas for kernel and user space data. This allows each address space to place pointer values of its address space in private regions associated with the shared data structures.</li>
<li>An address space opaque pointer type is provided to safely save pointer values in shared memory locations where necessary.</li>
<li>The single producer, single consumer circular buffer event queue shared between the transport and the core layer in the kernel is designed to work with the producer and consumer potentially in different address spaces. This is described in further detail in <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-bevq">The Buffer Event Queue</a>.</li>
</ul>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-match-bits"></a>
Match Bits for Buffer Identification</h2>
<p>The kernel Core module will maintain a unsigned integer counter per transfer machine, to generate unique match bits for passive bulk buffers associated with that transfer machine. The upper 12 match bits are reserved by the HLD to represent the transfer machine identifier. Therefore the counter is (64-12)=52 bits wide. The value of 0 is reserved for unsolicited receive messages, so the counter range is [1,0xfffffffffffff]. It is initialized to 1 and will wrap back to 1 when it reaches its upper bound.</p>
<p>The transport uses the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga6b079c8c33e3be851281f141ad23ce35">nlx_core_buf_passive_recv()</a> or the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga2d0eba66a9a2f182ff13c8986b53839f">nlx_core_buf_passive_send()</a> subroutines to stage passive buffers. Prior to initiating these operations, the transport should use the <a class="el" href="../../d8/de0/group___l_net_core.html#gaf8b803bcbff74c0d50e0efaebfd5d5ea">nlx_core_buf_desc_encode()</a> subroutine to generate new match bits for the passive buffer. The match bit counter will repeat over time, though after a very long while. It is the transport's responsibility to ensure that all of the passive buffers associated with a given transfer machine have unique match bits. The match bits should be encoded into the network buffer descriptor associated with the passive buffer.</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-tm-list"></a>
Transfer Machine Uniqueness</h2>
<p>The kernel Core module must ensure that all transfer machines on the host have unique transfer machine identifiers for a given NID/PID/Portal, regardless of the transport instance or network domain context in which these transfer machines are created. To support this, the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga3d6835b409bc7320ad692276a398f7c3">nlx_kcore_tms</a> list threads through all the kernel Core's per-TM private data structures. This list is private to the kernel Core, and is protected by the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga50c49f625237054c48c7417378a5d737">nlx_kcore_mutex</a>.</p>
<p>The same list helps in assigning dynamic transfer machine identifiers. The highest available value at the upper bound of the transfer machine identifier space is assigned dynamically. The logic takes into account the NID, PID and portal number of the new transfer machine when looking for an available transfer machine identifier. A single pass over the list is required to search for an available transfer machine identifier.</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-bevq"></a>
The Buffer Event Queue</h2>
<p>The kernel Core receives notification of the completion of a buffer operation through an LNet callback. The completion status is not directly conveyed to the transport, because the transport layer may have processor affinity constraints that are not met by the LNet callback thread; indeed, LNet does not even state if this callback is in a schedulable context.</p>
<p>Instead, the kernel Core module decouples the delivery of buffer operation completion to the transport from the LNet callback context by copying the result to an intermediate buffer event queue. The Core API provides the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine that the transport can use to poll for the presence of buffer events, and the <a class="el" href="../../d8/de0/group___l_net_core.html#gaea683e854b7a488bec4543247128289d">nlx_core_buf_event_get()</a> subroutine to recover the payload of the next available buffer event. See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a> for further details on these subroutines.</p>
<p>There is another advantage to this indirect delivery: to address the requirement to efficiently support a user space transport, the Core module keeps this queue in memory shared between the transport and the Core, eliminating the need for a user space transport to make an <code>ioctl</code> call to fetch the buffer event payload. The only <code>ioctl</code> call needed for a user space transport is to block waiting for buffer events to appear in the shared memory queue.</p>
<p>It is critical for proper operation, that there be an available buffer event structure when the LNet callback is invoked, or else the event cannot be delivered and will be lost. As the event queue is in shared memory, it is not possible, let alone desirable, to allocate a new buffer event structure in the callback context.</p>
<p>The Core API guarantees the delivery of buffer operation completion status by maintaining a "pool" of free buffer event structures for this purpose. It does so by keeping count of the total number of buffer event structures required to satisfy all outstanding operations, and adding additional such structures to the "pool" if necessary, when a new buffer operation is initiated. Likewise, the count is decremented for each buffer event delivered to the transport. Most buffers operations only need a single buffer event structure in which to return their operation result, but receive buffers may need more, depending on the individually configurable maximum number of messages that could be received in each receive buffer.</p>
<p>The pool and queue potentially span the kernel and user address spaces. There are two cases around the use of these data structures:</p>
<ul>
<li>Normal queue operation involves a single <em>producer</em>, in the kernel Core callback subroutine, and a single <em>consumer</em>, in the Core API <a class="el" href="../../d8/de0/group___l_net_core.html#gaea683e854b7a488bec4543247128289d">nlx_core_buf_event_get()</a> subroutine, which may be invoked either in the kernel or in user space.</li>
<li>The allocation of new buffer event structures to the "pool" is always done by the Core API buffer operation initiation subroutines invoked by the transport. The user space implementation of the Core API would have to arrange for these new structures to get mapped into the kernel at this time.</li>
</ul>
<p>The kernel Core module combines both the free "pool" and the result queue into a single data structure: a circular, single producer, single consumer buffer event queue. Details on this event queue are covered in the <a class="el" href="../../de/d4e/_l_netcqueue_d_l_d.html">LNet Buffer Event Circular Queue DLD.</a></p>
<p>The design makes a critical simplifying assumption, in that the transport will use exactly one thread to process events. This assumption implicitly serializes the delivery of the events associated with any given receive buffer, thus the last event which unlinks the buffer is guaranteed to be delivered after other events associated with that same buffer operation.</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-lnet-init"></a>
LNet Initialization and Finalization</h2>
<p>No initialization and finalization logic is required for LNet in the kernel for the following reasons:</p>
<ul>
<li>Use of the LNet kernel module is reference counted by the kernel.</li>
<li>The LNetInit() subroutine is automatically called when then LNet kernel module is loaded, and cannot be called multiple times.</li>
</ul>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-reg"></a>
LNet Buffer Registration</h2>
<p>No hardware optimization support is defined in the LNet API at this time but the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#gac9bfb3d66ff5adfe644fdd2aed9b7a3a">nlx_core_buf_register()</a> subroutine serves as a placeholder where any such optimizations could be made in the future. The <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga25a65acaf1535ea5e1fff9a18972cba4">nlx_core_buf_deregister()</a> subroutine would be used to release any allocated resources.</p>
<p>During buffer registration, the kernel Core API will translate the m0_net_bufvec into the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a4b74b8ac5bcb10e1ba2da04bc98048d0">nlx_kcore_buffer::kb_kiov</a> field of the buffer private data.</p>
<p>The kernel implementation of the Core API does not increment the page count of the buffer pages. The supposition here is that the buffers are allocated by Motr file system clients, and the Core API has no business imposing memory management policy beneath such a client.</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-tm-res"></a>
LNet Transfer Machine Resources</h2>
<p>A transfer machine is associated with the following LNet resources:</p><ul>
<li>An Event Queue (EQ). This is represented by the <a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a46760366658512a21eac66ccc282cd86">nlx_kcore_transfer_mc::ktm_eqh</a> handle.</li>
</ul>
<p>The <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga320b9bd08fca9515d270a582f7a2dc3f">nlx_core_tm_start()</a> subroutine creates the event handle. The <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga40d158d51d960ab794120b77560e06a3">nlx_core_tm_stop()</a> subroutine releases the handle. See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a> for more details on event processing.</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-buf-res"></a>
LNet Buffer Resources</h2>
<p>A network buffer is associated with a Memory Descriptor (MD). This is represented by the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a09dce61ba8ebe4ab6c3da1c432eae281">nlx_kcore_buffer::kb_mdh</a> handle. There may be a Match Entry (ME) associated with this MD for some operations, but when created, it is set up to unlink automatically when the MD is unlinked so it is not explicitly tracked.</p>
<p>All the buffer operation initiation subroutines of the kernel Core API create such MDs. Although an MD is set up to explicitly unlink upon completion, the value is saved in case an operation needs to be cancelled.</p>
<p>All MDs are associated with the EQ of the transfer machine (<a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a46760366658512a21eac66ccc282cd86">nlx_kcore_transfer_mc::ktm_eqh</a>).</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-ev"></a>
LNet Event Callback Processing</h2>
<p>LNet event queues are used with an event callback subroutine to avoid event loss. The callback subroutine overhead is fairly minimal, as it only copies out the event payload and arranges for subsequent asynchronous delivery. This, coupled with the fact that the circular buffer used works optimally with a single producer and single consumer resulted in the decision to use just one LNet EQ per transfer machine (<a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a46760366658512a21eac66ccc282cd86">nlx_kcore_transfer_mc::ktm_eqh</a>).</p>
<p>The EQ is created in the call to the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga320b9bd08fca9515d270a582f7a2dc3f">nlx_core_tm_start()</a> subroutine, and is freed in the call to the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga40d158d51d960ab794120b77560e06a3">nlx_core_tm_stop()</a> subroutine.</p>
<p>LNet requires that the callback subroutine be re-entrant and non-blocking, and not make any LNet API calls. Given that the circular queue assumes a single producer and single consumer, a spin lock is used to serialize access of the two EQs to the circular queue.</p>
<p>The event callback requires that the MD <code>user_ptr</code> field be set up to the address of the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html">nlx_kcore_buffer</a> data structure. Note that if an event has the <code>unlinked</code> field set then this will be the last event that LNet will post for the related operation, and the <code>user_ptr</code> field will be valid, so the callback can safely de-reference the field to determine the correct queue.</p>
<p>The callback subroutine does the following:</p>
<ol type="1">
<li>It will ignore <code>LNET_EVENT_SEND</code> events delivered as a result of a <code>LNetGet()</code> call if the <code>unlinked</code> field of the event is not set. If the <code>unlinked</code> field is set, the event could either be an out-of-order SEND (terminating a REPLY/SEND sequence), or the piggy-backed UNLINK on an in-order SEND. The two cases are distinguished by explicitly tracking the receipt of an out-of-order REPLY (in <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#ac2fb5d126eb8ef59dbf0615c1ad4b0f5">nlx_kcore_buffer::kb_ooo_reply</a>). An out-of-order SEND will be treated as though it is the terminating <code>LNET_EVENT_REPLY</code> event of a SEND/REPLY sequence.</li>
<li>It will not create an event in the circular queue for <code>LNET_EVENT_REPLY</code> events that do not have their <code>unlinked</code> field set. They indicate an out-of-sequence REPLY/SEND combination, and LNet will issue a valid SEND event subsequently. However, the receipt of such an REPLY will be remembered in <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#ac2fb5d126eb8ef59dbf0615c1ad4b0f5">nlx_kcore_buffer::kb_ooo_reply</a>, and its payload in the other "ooo" fields, so that when the out-of-order SEND arrives, this data can be used to generate the circular queue event.</li>
<li>It will ignore <code>LNET_EVENT_ACK</code> events.</li>
<li>It obtains the <a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a5dd563a1e07b32f10185e50a08e4bd41">nlx_kcore_transfer_mc::ktm_bevq_lock</a> spin lock.</li>
<li>The <a class="el" href="../../dd/d08/group__bevcqueue.html#ga6027e82fa54371c2e9335f5366455adf">bev_cqueue_pnext()</a> subroutine is then used to locate the next buffer event structure in the circular buffer event queue which will be used to return the result.</li>
<li>It copies the event payload from the LNet event to the buffer event structure. This includes the value of the <code>unlinked</code> field of the event, which must be copied to the <a class="el" href="../../d1/d4b/structnlx__core__buffer__event.html#a1d56cd87afd3208540b55587918a3656">nlx_core_buffer_event::cbe_unlinked</a> field. For <code>LNET_EVENT_UNLINK</code> events, a <code>-ECANCELED</code> value is written to the <a class="el" href="../../d1/d4b/structnlx__core__buffer__event.html#a80a97200075356c56273af35f86adb46">nlx_core_buffer_event::cbe_status</a> field and the <a class="el" href="../../d1/d4b/structnlx__core__buffer__event.html#a1d56cd87afd3208540b55587918a3656">nlx_core_buffer_event::cbe_unlinked</a> field set to true. For <code>LNET_EVENT_PUT</code> events corresponding to unsolicited message delivery, the sender's TMID and Portal are encoded in the hdr_data. These values are decoded into the <a class="el" href="../../d1/d4b/structnlx__core__buffer__event.html#a0b35bd86498b31e5fdd8a835087fbcd2">nlx_core_buffer_event::cbe_sender</a>, along with the initiator's NID and PID. The <a class="el" href="../../d1/d4b/structnlx__core__buffer__event.html#a0b35bd86498b31e5fdd8a835087fbcd2">nlx_core_buffer_event::cbe_sender</a> is not set for other events.</li>
<li>It invokes the <a class="el" href="../../dd/d08/group__bevcqueue.html#gaef877c0746747aab043617177b5973df">bev_cqueue_put()</a> subroutine to "produce" the event in the circular queue.</li>
<li>It releases the <a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a5dd563a1e07b32f10185e50a08e4bd41">nlx_kcore_transfer_mc::ktm_bevq_lock</a> spin lock.</li>
<li>It signals the nlx_kcore_transfer_mc::ktm_sem semaphore with the <a class="el" href="../../d1/d5d/group__semaphore.html#gaec2688b125e30e354e0d388c6381b81d">m0_semaphore_up()</a> subroutine.</li>
</ol>
<p>The (single) transport layer event handler thread blocks on the Core transfer machine semaphore in the Core API <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine which uses the <a class="el" href="../../d1/d5d/group__semaphore.html#gac475887387f514fc84e78c3da285e2af">m0_semaphore_timeddown()</a> subroutine internally to wait on the semaphore. When the Core API subroutine returns with an indication of the presence of events, the event handler thread consumes all the pending events with multiple calls to the Core API <a class="el" href="../../d8/de0/group___l_net_core.html#gaea683e854b7a488bec4543247128289d">nlx_core_buf_event_get()</a> subroutine, which uses the <a class="el" href="../../dd/d08/group__bevcqueue.html#ga77e31d64b61358e7d0d559a774ceb639">bev_cqueue_get()</a> subroutine internally to get the next buffer event. Then the event handler thread repeats the call to the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine to once again block for additional events.</p>
<p>In the case of the user space transport, the blocking on the semaphore is done indirectly by the user space Core API's device driver in the kernel. It is required by the HLD that as many events as possible be consumed before the next context switch to the kernel must be made. To support this, the kernel Core <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine takes a few additional steps to minimize the chance of returning when the queue is empty. After it obtains the semaphore with the <a class="el" href="../../d1/d5d/group__semaphore.html#gac475887387f514fc84e78c3da285e2af">m0_semaphore_timeddown()</a> subroutine (i.e. the <em>P</em> operation succeeds), it attempts to clear the semaphore count by repeatedly calling the <a class="el" href="../../d1/d5d/group__semaphore.html#gad12ecf092c39b96c7fb5815004a3b384">m0_semaphore_trydown()</a> subroutine until it fails. It then checks the circular queue, and only if not empty will it return. This is illustrated with the following pseudo-code: </p><div class="fragment"><div class="line"><span class="keywordflow">do</span> {</div><div class="line">   <a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> = <a class="code" href="../../d1/d5d/group__semaphore.html#gac475887387f514fc84e78c3da285e2af">m0_semaphore_timeddown</a>(&amp;<a class="code" href="../../de/d9e/cm_2ut_2cp_8c.html#ac1217e6a5dbbdde0fc24bd1b11fb0f0a">sem</a>, &amp;<a class="code" href="../../d9/de6/group__console.html#gab5627d8d8b095c198e2523c44ca380ac">timeout</a>);</div><div class="line">   <span class="keywordflow">if</span> (<a class="code" href="../../d7/db8/cm_2repreb_2trigger__fop_8h.html#ac6509c6fe4cbf7bde170597172f8a288">rc</a> &lt; 0)</div><div class="line">       <span class="keywordflow">break</span>; <span class="comment">// timed out</span></div><div class="line">   <span class="keywordflow">while</span> (<a class="code" href="../../d1/d5d/group__semaphore.html#gad12ecf092c39b96c7fb5815004a3b384">m0_semaphore_trydown</a>(&amp;<a class="code" href="../../de/d9e/cm_2ut_2cp_8c.html#ac1217e6a5dbbdde0fc24bd1b11fb0f0a">sem</a>))</div><div class="line">       ; <span class="comment">// exhaust the semaphore</span></div><div class="line">} <span class="keywordflow">while</span> (<a class="code" href="../../dd/d08/group__bevcqueue.html#ga5d24e1b0bc217d8d53b11f0afcdcce03">bev_cqueue_is_empty</a>(&amp;<a class="code" href="../../d1/d41/ut_2rwlock_8c.html#a1d2a9f68c117ca7f7fdcb220f4c08fa4">q</a>)); <span class="comment">// loop if empty</span></div></div><!-- fragment --><p> (The C++ style comments are used because of doxygen only - they are not permitted by the Motr style guide.)</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-recv"></a>
LNet Receiving Unsolicited Messages</h2>
<ol type="1">
<li>Create an ME with <code>LNetMEAttach()</code> for the transfer machine and specify the portal, match and ignore bits. All receive buffers for a given TM will use a match bit value equal to the TM identifier in the higher order bits and zeros for the other bits. No ignore bits are set. The ME should be set up to unlink automatically as it will be used for all receive buffers of this transfer machine. The ME entry should be positioned at the end of the portal match list. There is no need to retain the ME handle beyond the subsequent <code>LNetMDAttach()</code> call.</li>
<li>Create and attach an MD to the ME using <code>LNetMDAttach()</code>. The MD is set up to unlink automatically. Save the MD handle in the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a09dce61ba8ebe4ab6c3da1c432eae281">nlx_kcore_buffer::kb_mdh</a> field. Set up the fields of the <code>lnet_md_t</code> argument as follows:<ul>
<li>Set the <code>eq_handle</code> to identify the EQ associated with the transfer machine (<a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a46760366658512a21eac66ccc282cd86">nlx_kcore_transfer_mc::ktm_eqh</a>).</li>
<li>Set the address of the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html">nlx_kcore_buffer</a> in the <code>user_ptr</code> field.</li>
<li>Pass in the KIOV from the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a4b74b8ac5bcb10e1ba2da04bc98048d0">nlx_kcore_buffer::kb_kiov</a>.</li>
<li>Set the <code>threshold</code> value to the nlx_kcore_buffer::kb_max_recv_msgs value.</li>
<li>Set the <code>max_size</code> value to the nlx_kcore_buffer::kb_min_recv_size value.</li>
<li>Set the <code>LNET_MD_OP_PUT</code>, <code>LNET_MD_MAX_SIZE</code> and <code>LNET_MD_KIOV</code> flags in the <code>options</code> field.</li>
</ul>
</li>
<li>When a message arrives, an <code>LNET_EVENT_PUT</code> event will be delivered to the event queue, and will be processed as described in <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a>.</li>
</ol>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-send"></a>
LNet Sending Messages</h2>
<ol type="1">
<li>Create an MD using <code>LNetMDBind()</code> with each invocation of the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga70f259a426d073a46ca6a477dd640621">nlx_core_buf_msg_send()</a> subroutine. The MD is set up to unlink automatically. Save the MD handle in the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a09dce61ba8ebe4ab6c3da1c432eae281">nlx_kcore_buffer::kb_mdh</a> field. Set up the fields of the <code>lnet_md_t</code> argument as follows:<ul>
<li>Set the <code>eq_handle</code> to identify the EQ associated with the transfer machine (<a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a46760366658512a21eac66ccc282cd86">nlx_kcore_transfer_mc::ktm_eqh</a>).</li>
<li>Set the address of the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html">nlx_kcore_buffer</a> in the <code>user_ptr</code> field.</li>
<li>Pass in the KIOV from the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a4b74b8ac5bcb10e1ba2da04bc98048d0">nlx_kcore_buffer::kb_kiov</a>. The number of entries in the KIOV and the length field in the last element of the vector must be adjusted to reflect the desired byte count.</li>
<li>Set the <code>LNET_MD_KIOV</code> flag in the <code>options</code> field.</li>
</ul>
</li>
<li>Use the <code>LNetPut()</code> subroutine to send the MD to the destination. The match bits must set to the destination TM identifier in the higher order bits and zeros for the other bits. The hdr_data must be set to a value encoding the TMID (in the upper bits, like the match bits) and the portal (in the lower bits). No acknowledgment should be requested.</li>
<li>When the message is sent, an <code>LNET_EVENT_SEND</code> event will be delivered to the event queue, and processed as described in <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a>. <dl class="section note"><dt>Note</dt><dd>The event does not indicate if the recipient was able to save the data, but merely that it left the host.</dd></dl>
</li>
</ol>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-passive"></a>
LNet Staging Passive Bulk Buffers</h2>
<ol type="1">
<li>Prior to invoking the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga6b079c8c33e3be851281f141ad23ce35">nlx_core_buf_passive_recv()</a> or the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga2d0eba66a9a2f182ff13c8986b53839f">nlx_core_buf_passive_send()</a> subroutines, the transport should use the <a class="el" href="../../d8/de0/group___l_net_core.html#gaf8b803bcbff74c0d50e0efaebfd5d5ea">nlx_core_buf_desc_encode()</a> subroutine to assign unique match bits to the passive buffer. See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-match-bits">Match Bits for Buffer Identification</a> for details. The match bits should be encoded into the network buffer descriptor and independently conveyed to the remote active transport. The network descriptor also encodes the number of bytes to be transferred.</li>
<li>Create an ME using <code>LNetMEAttach()</code>. Specify the portal and match_id fields as appropriate for the transfer machine. The buffer's match bits are obtained from the <a class="el" href="../../d7/df3/structnlx__core__buffer.html#af0cf429614f5d9e5e84f81e2232c9cc1">nlx_core_buffer::cb_match_bits</a> field. No ignore bits are set. The ME should be set up to unlink automatically, so there is no need to save the handle for later use. The ME should be positioned at the end of the portal match list.</li>
<li>Create and attach an MD to the ME using <code>LNetMDAttach()</code> with each invocation of the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga6b079c8c33e3be851281f141ad23ce35">nlx_core_buf_passive_recv()</a> or the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga2d0eba66a9a2f182ff13c8986b53839f">nlx_core_buf_passive_send()</a> subroutines. The MD is set up to unlink automatically. Save the MD handle in the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a09dce61ba8ebe4ab6c3da1c432eae281">nlx_kcore_buffer::kb_mdh</a> field. Set up the fields of the <code>lnet_md_t</code> argument as follows:<ul>
<li>Set the <code>eq_handle</code> to identify the EQ associated with the transfer machine (<a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a46760366658512a21eac66ccc282cd86">nlx_kcore_transfer_mc::ktm_eqh</a>).</li>
<li>Set the address of the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html">nlx_kcore_buffer</a> in the <code>user_ptr</code> field.</li>
<li>Pass in the KIOV from the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a4b74b8ac5bcb10e1ba2da04bc98048d0">nlx_kcore_buffer::kb_kiov</a>.</li>
<li>Set the <code>LNET_MD_KIOV</code> flag in the <code>options</code> field, along with either the <code>LNET_MD_OP_PUT</code> or the <code>LNET_MD_OP_GET</code> flag according to the direction of data transfer.</li>
</ul>
</li>
<li>When the bulk data transfer completes, either an <code>LNET_EVENT_PUT</code> or an <code>LNET_EVENT_GET</code> event will be delivered to the event queue, and will be processed as described in <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a>.</li>
</ol>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-active"></a>
LNet Active Bulk Read or Write</h2>
<ol type="1">
<li>Prior to invoking the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#gab0f7d2d447f931f538e235d40787c2c3">nlx_core_buf_active_recv()</a> or <a class="el" href="../../d6/d8a/group___k_l_net_core.html#gaa3f0a51bdcf5fb39721155d962248363">nlx_core_buf_active_send()</a> subroutines, the transport should put the match bits of the remote passive buffer into the <a class="el" href="../../d7/df3/structnlx__core__buffer.html#af0cf429614f5d9e5e84f81e2232c9cc1">nlx_core_buffer::cb_match_bits</a> field. The destination address of the remote transfer machine with the passive buffer should be set in the <a class="el" href="../../d7/df3/structnlx__core__buffer.html#ab80e58c4a220bd8bdf722a34b3acb189">nlx_core_buffer::cb_addr</a> field.</li>
<li>Create an MD using <code>LNetMDBind()</code> with each invocation of the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#gab0f7d2d447f931f538e235d40787c2c3">nlx_core_buf_active_recv()</a> or <a class="el" href="../../d6/d8a/group___k_l_net_core.html#gaa3f0a51bdcf5fb39721155d962248363">nlx_core_buf_active_send()</a> subroutines. The MD is set up to unlink automatically. Save the MD handle in the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a09dce61ba8ebe4ab6c3da1c432eae281">nlx_kcore_buffer::kb_mdh</a> field. Set up the fields of the <code>lnet_md_t</code> argument as follows:<ul>
<li>Set the <code>eq_handle</code> to identify the EQ associated with the transfer machine (<a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a46760366658512a21eac66ccc282cd86">nlx_kcore_transfer_mc::ktm_eqh</a>).</li>
<li>Set the address of the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html">nlx_kcore_buffer</a> in the <code>user_ptr</code> field.</li>
<li>Pass in the KIOV from the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a4b74b8ac5bcb10e1ba2da04bc98048d0">nlx_kcore_buffer::kb_kiov</a>. The number of entries in the KIOV and the length field in the last element of the vector must be adjusted to reflect the desired byte count.</li>
<li>Set the <code>LNET_MD_KIOV</code> flag in the <code>options</code> field.</li>
<li>In case of an active read, which uses <code>LNetGet()</code>, set the threshold value to 2 to accommodate both the SEND and the REPLY events. Otherwise set it to 1.</li>
</ul>
</li>
<li>Use the <code>LNetGet()</code> subroutine to initiate the active read or the <code>LNetPut()</code> subroutine to initiate the active write. The <code>hdr_data</code> is set to 0 in the case of <code>LNetPut()</code>. No acknowledgment should be requested. In the case of an <code>LNetGet()</code>, the field used to track out-of-order REPLY events (<a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#ac2fb5d126eb8ef59dbf0615c1ad4b0f5">nlx_kcore_buffer::kb_ooo_reply</a>) should be cleared before the operation is initiated.</li>
<li>When a response to the <code>LNetGet()</code> or <code>LNetPut()</code> call completes, an <code>LNET_EVENT_SEND</code> event will be delivered to the event queue and should typically be ignored in the case of <code>LNetGet()</code>. See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a> for details.</li>
<li><p class="startli">When the bulk data transfer for <code>LNetGet()</code> completes, an <code>LNET_EVENT_REPLY</code> event will be delivered to the event queue, and will be processed as described in <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a>.</p>
<dl class="section note"><dt>Note</dt><dd>LNet does not guarantee the order of the SEND and REPLY events associated with the <code>LNetGet()</code> operation. Also note that in the case of an <code>LNetGet()</code> operation, the SEND event does not indicate if the recipient was able to save the data, but merely that the request left the host.</dd></dl>
</li>
</ol>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-lnet-cancel"></a>
LNet Canceling Operations</h2>
<p>The kernel Core module provides no timeout capability. The transport may initiate a cancel operation using the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#gadc89ed4c9201fee7e524777331f4b7ad">nlx_core_buf_del()</a> subroutine.</p>
<p>This will result in an <code>LNetMDUnlink()</code> subroutine call being issued for the buffer MD saved in the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html#a09dce61ba8ebe4ab6c3da1c432eae281">nlx_kcore_buffer::kb_mdh</a> field. Cancellation may or may not take place - it depends upon whether the operation has started, and there is a race condition in making this call and concurrent delivery of an event associated with the MD.</p>
<p>Assuming success, the next event delivered for the buffer concerned will either be a <code>LNET_EVENT_UNLINK</code> event or the <code>unlinked</code> field will be set in the next completion event for the buffer. The events will be processed as described in <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a>.</p>
<p>LNet properly handles the race condition between the automatic unlink of the MD and a call to <code>LNetMDUnlink()</code>.</p>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-state"></a>
State Specification</h2>
<ul>
<li>The kernel Core module relies on the networking data structures to maintain the linkage between the data structures used by the Core module. It maintains no lists through data structures itself. As such, these lists can only be navigated by the Core API subroutines invoked by the transport (the "upper" layer) and not by the Core module's LNet callback subroutine (the "lower" layer).</li>
<li>The kernel Core API maintains a count of the total number of buffer event structures needed. This should be tested by the Core API's transfer machine invariant subroutine before returning from any buffer operation initiation call, and before returning from the <a class="el" href="../../d8/de0/group___l_net_core.html#gaea683e854b7a488bec4543247128289d">nlx_core_buf_event_get()</a> subroutine.</li>
<li>The kernel Core layer module depends on the LNet module in the kernel at run time. This dependency is captured by the Linux kernel module support that reference counts the usage of dependent modules.</li>
<li>The kernel Core layer modules explicitly tracks the events received for <code>LNetGet()</code> calls, in the <a class="el" href="../../d5/daa/structnlx__kcore__buffer.html">nlx_kcore_buffer</a> data structure associated with the call. This is because there are two events (SEND and REPLY) that are returned for this operation, and LNet does not guarantee their order of arrival, and the event processing logic is set up such that a circular buffer event must be created only upon receipt of the last operation event. Complicating the issue is that a cancellation response could be piggy-backed onto an in-order SEND. See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-ev">LNet Event Callback Processing</a> and <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-active">LNet Active Bulk Read or Write</a> for details.</li>
</ul>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-thread"></a>
Threading and Concurrency Model</h2>
<ol type="1">
<li>Generally speaking, API calls within the transport address space are protected by the serialization of the Motr Networking layer, typically the transfer machine mutex or the domain mutex. The <a class="el" href="../../d8/de0/group___l_net_core.html#gaf8b803bcbff74c0d50e0efaebfd5d5ea">nlx_core_buf_desc_encode()</a> subroutine, for example, is fully protected by the transfer machine mutex held across the <a class="el" href="../../d9/dd2/group__net.html#gacce89dfe5af29f0c271b458408c6e57e">m0_net_buffer_add()</a> subroutine call, so implicitly protects the match bit counter in the kernel Core's per TM private data.</li>
<li>The Motr Networking layer serialization does not always suffice, as the kernel Core module has to support concurrent multiple transport instances in kernel and user space. Fortunately, the LNet API intrinsically provides considerable serialization support to the Core, as transfer machines are defined by the HLD to have disjoint addresses.</li>
<li>Enforcement of the disjoint address semantics are protected by the kernel Core's <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga50c49f625237054c48c7417378a5d737">nlx_kcore_mutex</a> lock. The <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga320b9bd08fca9515d270a582f7a2dc3f">nlx_core_tm_start()</a> and <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga40d158d51d960ab794120b77560e06a3">nlx_core_tm_stop()</a> subroutines use this mutex internally for serialization and operation on the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga3d6835b409bc7320ad692276a398f7c3">nlx_kcore_tms</a> list threaded through the kernel Core's per-TM private data.</li>
<li>The kernel Core module registers a callback subroutine with the LNet EQ defined per transfer machine. LNet requires that this subroutine be reentrant and non-blocking. The circular buffer event queue accessed from the callback requires a single producer, so the <a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a5dd563a1e07b32f10185e50a08e4bd41">nlx_kcore_transfer_mc::ktm_bevq_lock</a> spin lock is used to serialize its use across possible concurrent invocations. The time spent in the lock is minimal.</li>
<li>The Core API does not support callbacks to indicate completion of an asynchronous buffer operation. Instead, the transport application must invoke the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine to block waiting for buffer events. Internally this call waits on the nlx_kcore_transfer_mc::ktm_sem semaphore. The semaphore is incremented each time an event is added to the buffer event queue.</li>
<li>The event payload is actually delivered via a per transfer machine single producer, single consumer, lock-free circular buffer event queue. The only requirement for failure free operation is to ensure that there are sufficient event structures pre-allocated to the queue, plus one more to support the circular semantics. Multiple events may be dequeued between each call to the <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga327d60c2c88dba4beb81eaada363e4fa">nlx_core_buf_event_wait()</a> subroutine. Each such event is fetched by a call to the <a class="el" href="../../d8/de0/group___l_net_core.html#gaea683e854b7a488bec4543247128289d">nlx_core_buf_event_get()</a> subroutine, until the queue is exhausted. Note that the queue exists in memory shared between the transport and the kernel Core; the transport could be in the kernel or in user space.</li>
<li>The API assumes that only a single transport thread will handle event processing. This is a critical assumption in the support for multiple messages in a single receive buffer, as it implicitly serializes the delivery of the events associated with any given receive buffer, thus the last event which unlinks the buffer is guaranteed to be delivered last.</li>
<li>The Motr LNet transport driver releases all kernel resources associated with a user space domain when the device is released (the final close). It must not release buffer event objects or transfer machines while the LNet EQ callback requires them. The Kernel Core LNet EQ callback, <a class="el" href="../../d6/d8a/group___k_l_net_core.html#ga9978273be1fdc7dfc1d458c1aa615dd5">nlx_kcore_eq_cb()</a>, resets the association between a buffer and a transfer machine and increments the nlx_kcore_transfer_mc::ktm_sem semaphore while holding the <a class="el" href="../../d5/d0b/structnlx__kcore__transfer__mc.html#a5dd563a1e07b32f10185e50a08e4bd41">nlx_kcore_transfer_mc::ktm_bevq_lock</a>, and the callback never refers to either object after releasing the lock. The driver layer holds this lock as well while verifying that a buffer is not associated with a transfer machine, and, outside the lock, decrements the semaphore to wait for buffers to be unlinked by LNet (the device is being released, so no other thread will be decrementing the semaphore). This assures the buffer event objects and the transfer machine will remain until the final LNet event is delivered.</li>
<li>LNet properly handles the race condition between the automatic unlink of the MD and a call to <code>LNetMDUnlink()</code>.</li>
</ol>
<h2><a class="anchor" id="KLNetCoreDLD-lspec-numa"></a>
NUMA optimizations</h2>
<p>The LNet transport will initiate calls to the API on threads that may have specific process affinity assigned.</p>
<p>LNet offers no direct NUMA optimizations. In particular, event callbacks cannot be constrained to have any specific processor affinity. The API compensates for this lack of support by providing a level of indirection in event delivery: its callback handler simply copies the LNet event payload to an event delivery queue and notifies a transport event processing thread of the presence of the event. (See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-bevq">The Buffer Event Queue</a> above). The transport event processing threads can be constrained to have any desired processor affinity.</p>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-conformance"></a>
Conformance</h1>
<ul>
<li><b>i.m0.net.lnet.buffer-registration</b> See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-reg">LNet Buffer Registration</a>.</li>
<li><b>i.m0.net.xprt.lnet.end-point-address</b> The <a class="el" href="../../d8/de0/group___l_net_core.html#ga9fa65b9a7f3ca1f1a79066e731fddd2a">nlx_core_ep_addr_encode()</a> and <a class="el" href="../../d8/de0/group___l_net_core.html#gadcf9e5c3e6a5615f874f8df656cc0298">nlx_core_ep_addr_decode()</a> provide this functionality.</li>
<li><b>i.m0.net.xprt.lnet.multiple-messages-in-buffer</b> See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-recv">LNet Receiving Unsolicited Messages</a>.</li>
<li><b>i.m0.net.xprt.lnet.dynamic-address-assignment</b> See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-tm-list">Transfer Machine Uniqueness</a>.</li>
<li><b>i.m0.net.xprt.lnet.user-space</b> See <a class="el" href="../../db/dd7/_k_l_net_core_d_l_d.html#KLNetCoreDLD-lspec-userspace">Support for User Space Transports</a>.</li>
<li><b>i.m0.net.xprt.lnet.user.no-gpl</b> See the <a class="el" href="../../da/d12/_l_net_core_d_l_d-fspec.html">Functional Specification</a>; no LNet headers are exposed by the Core API.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-ut"></a>
Unit Tests</h1>
<p>The testing strategy is 2 pronged:</p><ul>
<li>Tests with a fake LNet API. These tests will intercept the LNet subroutine calls. The real LNet data structures will be used by the Core API.</li>
<li>Tests with the real LNet API using the TCP loop back address. These tests will use the TCP loop back address. LNet on the test machine must be configured with the <code>"tcp"</code> network.</li>
</ul>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000093">Test:</a></b></dt><dd>The correct sequence of LNet operations are issued for each type of buffer operation with a fake LNet API.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000094">Test:</a></b></dt><dd>The callback subroutine properly delivers events to the buffer event queue, including single and multiple events for receive buffers with a fake LNet API.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000095">Test:</a></b></dt><dd>The dynamic assignment of transfer machine identifiers with a fake LNet API.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000096">Test:</a></b></dt><dd>Test the parsing of LNet addresses with the real LNet API.</dd></dl>
<dl class="test"><dt><b><a class="el" href="../../d4/df6/test.html#_test000097">Test:</a></b></dt><dd>Test each type of buffer operation, including single and multiple events for receive buffers with the real LNet API.</dd></dl>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-st"></a>
System Tests</h1>
<p>System testing will be performed as part of the transport operation system test.</p>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-O"></a>
Analysis</h1>
<ul>
<li>Dynamic transfer machine identifier assignment is proportional to the number of transfer machines defined on the server, including kernel and all process space LNet transport instances.</li>
<li>The time taken to process an LNet event callback is in constant time.</li>
<li>The time taken for the transport to dequeue a pending buffer event depends upon the operating system scheduler. The algorithmic processing involved is in constant time.</li>
<li>The time taken to register a buffer is in constant time. The reference count of the buffer pages is not incremented, so there are no VM subsystem imposed delays.</li>
<li>The time taken to process outbound buffer operations is unpredictable, and depends, at the minimum, on current system load, other LNet users, and on the network load.</li>
</ul>
<hr/>
 <h1><a class="anchor" id="KLNetCoreDLD-ref"></a>
References</h1>
<ul>
<li>HLD of Motr LNet Transport : For documentation links, please refer to this file : doc/motr-design-doc-list.rst</li>
<li>The LNet API. </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../d3/dd6/_d_l_d_i_x.html">Detailed Designs</a></li><li class="navelem"><a class="el" href="../../d6/de0/_l_net_d_l_d.html">LNet Transport DLD</a></li>
    <li class="footer">Generated on Thu Apr 14 2022 14:03:26 for Motr by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="../../doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
